# ğŸ« Deep Learning for Automated Multi-Label Chest X-Ray Diagnosis

**Student ID:** 15700249  
**Module:** 7150CEM Data Science Project  
**University:** Coventry University

## ğŸ“‹ Project Overview

This project implements an intelligent clinical decision support system for automated multi-label classification of chest X-ray pathologies using deep learning. The system combines DenseNet-121 with attention mechanisms and Grad-CAM explainability to detect 14 thoracic conditions with clinical-grade accuracy.

### Key Features

- âœ… **Multi-Label Classification**: Simultaneously detects 14 thoracic pathologies
- âœ… **Attention Mechanisms**: Squeeze-and-Excitation + Spatial Attention
- âœ… **Visual Explainability**: Grad-CAM heatmaps for interpretability
- âœ… **Clinical Interface**: Interactive Streamlit web application
- âœ… **High Performance**: <10 second inference, >0.85 AUROC target

### Detected Pathologies

1. Atelectasis
2. Cardiomegaly
3. Consolidation
4. Edema
5. Effusion
6. Emphysema
7. Fibrosis
8. Infiltration
9. Mass
10. Nodule
11. Pleural Thickening
12. Pneumonia
13. Pneumothorax
14. No Finding

---

## ğŸš€ Quick Start Guide for MacBook

### Prerequisites

- macOS 11.0 or later
- Python 3.8+ installed
- Minimum 50GB free disk space (for dataset)
- 8GB+ RAM recommended
- VS Code installed

### Step 1: Initial Setup

```bash
# Open Terminal (âŒ˜ + Space, type "Terminal")

# Navigate to your desired location
cd ~/Documents

# Clone or create project directory
mkdir chest-xray-diagnosis
cd chest-xray-diagnosis

# Make setup script executable
chmod +x setup.sh

# Run setup script
./setup.sh
```

### Step 2: Download Dataset

The NIH ChestX-ray14 dataset is required for training.

**Option A: Manual Download**

1. Visit: https://nihcc.app.box.com/v/ChestXray-NIHCC
2. Download files:
   - `Data_Entry_2017.csv`
   - `images_001.tar.gz` through `images_012.tar.gz`

3. Extract images:
```bash
cd data/raw
mkdir images

# Extract all tar files
for i in {001..012}; do
    tar -xzf images_${i}.tar.gz -C images/
    echo "Extracted images_${i}.tar.gz"
done

# Move CSV file
mv Data_Entry_2017.csv data/raw/
```

**Option B: Using wget (if available)**

```bash
cd data/raw

# Download metadata
wget https://nihcc.app.box.com/shared/static/vfk49d74nhbxq3nqjg0900w5nvkorp5c.csv -O Data_Entry_2017.csv

# Note: Image files are too large for direct wget
# Use Manual Download for image files
```

---

## ğŸ’» Complete Workflow Commands

### 1. Activate Environment

**Every time you start working, activate the virtual environment:**

```bash
cd chest-xray-diagnosis
source venv/bin/activate
```

You should see `(venv)` in your terminal prompt.

### 2. Data Preprocessing

```bash
# Run data preprocessing to create train/val/test splits
python src/data_preprocessing.py
```

**Expected Output:**
- Creates stratified splits (70% train, 15% val, 15% test)
- Saves splits to `data/splits/`
- Computes class weights for weighted loss
- Takes ~5-10 minutes

### 3. Model Training

```bash
# Start training (this will take 48-60 hours on GPU, longer on CPU)
python src/train.py

# To run in background and save output:
nohup python src/train.py > training.log 2>&1 &

# Monitor training progress:
tail -f training.log

# Or use TensorBoard:
tensorboard --logdir=runs
# Then open http://localhost:6006 in browser
```

**Training Options:**

```bash
# Resume training from checkpoint
python src/train.py --resume models/checkpoints/checkpoint_epoch_50.pth

# Train with specific GPU (if multiple available)
CUDA_VISIBLE_DEVICES=0 python src/train.py
```

**Expected Training Time:**
- **With NVIDIA GPU**: 48-60 hours
- **With Apple Silicon (MPS)**: 60-80 hours
- **CPU only**: 200+ hours (not recommended)

### 4. Model Evaluation

```bash
# Evaluate trained model on test set
python src/evaluate.py

# Evaluate with subgroup analysis
python src/evaluate.py --subgroup-analysis

# Generate comprehensive report
python src/evaluate.py --full-report
```

**Generated Outputs:**
- Test metrics (AUROC, sensitivity, specificity)
- ROC curves for all classes
- Confusion matrices
- Subgroup analysis (age, gender)
- Performance report (JSON + TXT)

### 5. Generate Grad-CAM Visualizations

```bash
# Generate Grad-CAM heatmaps for 50 samples
python src/gradcam.py

# Generate for specific number of samples
python src/gradcam.py --num-samples 100

# Generate for specific class
python src/gradcam.py --class-name Pneumonia
```

**Output Location:** `results/gradcam_outputs/`

### 6. Launch Clinical Interface

```bash
# Start Streamlit application
streamlit run streamlit_app/app.py

# Application will open in your browser automatically
# If not, navigate to: http://localhost:8501
```

**Interface Features:**
- Upload chest X-ray images
- Real-time AI diagnosis
- Interactive Grad-CAM visualizations
- Confidence scores
- Clinical report generation
- Export results

---

## ğŸ“ Project Structure

```
chest-xray-diagnosis/
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                          # Original NIH dataset
â”‚   â”‚   â”œâ”€â”€ images/                   # All chest X-ray images
â”‚   â”‚   â””â”€â”€ Data_Entry_2017.csv       # Metadata file
â”‚   â”œâ”€â”€ processed/                    # Preprocessed data (auto-generated)
â”‚   â””â”€â”€ splits/                       # Train/val/test splits (auto-generated)
â”‚       â”œâ”€â”€ train.csv
â”‚       â”œâ”€â”€ val.csv
â”‚       â”œâ”€â”€ test.csv
â”‚       â””â”€â”€ class_weights.json
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ checkpoints/                  # Training checkpoints
â”‚   â”‚   â””â”€â”€ checkpoint_epoch_*.pth
â”‚   â””â”€â”€ best_model.pth                # Best performing model
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ config.py                     # Configuration settings
â”‚   â”œâ”€â”€ data_preprocessing.py         # Data loading & preprocessing
â”‚   â”œâ”€â”€ model.py                      # DenseNet-121 architecture
â”‚   â”œâ”€â”€ train.py                      # Training pipeline
â”‚   â”œâ”€â”€ evaluate.py                   # Evaluation metrics
â”‚   â”œâ”€â”€ gradcam.py                    # Grad-CAM implementation
â”‚   â””â”€â”€ utils.py                      # Helper functions
â”‚
â”œâ”€â”€ streamlit_app/
â”‚   â”œâ”€â”€ app.py                        # Main Streamlit interface
â”‚   â”œâ”€â”€ components.py                 # UI components
â”‚   â””â”€â”€ assets/                       # Images, CSS, etc.
â”‚
â”œâ”€â”€ results/
â”‚   â”œâ”€â”€ figures/                      # Generated plots
â”‚   â”œâ”€â”€ metrics/                      # Performance metrics
â”‚   â””â”€â”€ gradcam_outputs/              # Grad-CAM visualizations
â”‚
â”œâ”€â”€ notebooks/                        # Jupyter notebooks for analysis
â”‚   â”œâ”€â”€ 01_data_exploration.ipynb
â”‚   â”œâ”€â”€ 02_model_analysis.ipynb
â”‚   â””â”€â”€ 03_results_visualization.ipynb
â”‚
â”œâ”€â”€ tests/                            # Unit tests
â”‚   â”œâ”€â”€ test_model.py
â”‚   â””â”€â”€ test_preprocessing.py
â”‚
â”œâ”€â”€ requirements.txt                  # Python dependencies
â”œâ”€â”€ setup.sh                          # Setup script
â”œâ”€â”€ README.md                         # This file
â”œâ”€â”€ .gitignore                        # Git ignore rules
â””â”€â”€ training.log                      # Training logs (generated)
```

---

## âš™ï¸ Configuration

Edit `src/config.py` to modify:

### Key Parameters

```python
# Model Architecture
BACKBONE = 'densenet121'
IMAGE_SIZE = 512
NUM_CLASSES = 14

# Training
BATCH_SIZE = 32           # Reduce if out of memory
NUM_EPOCHS = 100
LEARNING_RATE = 1e-4
DROPOUT_RATE = 0.4

# Performance Targets
TARGET_AUROC = 0.85
TARGET_SENSITIVITY = 0.90
TARGET_SPECIFICITY = 0.85
```

### Memory Optimization

If you encounter memory issues:

```python
# In config.py, reduce:
BATCH_SIZE = 16            # Instead of 32
NUM_WORKERS = 2            # Instead of 4
USE_MIXED_PRECISION = True # Enable if supported
```

---

## ğŸ” Monitoring Training

### Using TensorBoard

```bash
# Start TensorBoard
tensorboard --logdir=runs --port=6006

# Open in browser
open http://localhost:6006
```

**Metrics Available:**
- Training loss (per batch)
- Validation loss (per epoch)
- Validation AUROC (per epoch)
- Learning rate schedule
- Per-class AUROC

### Training Progress Logs

```bash
# Real-time monitoring
tail -f training.log

# Search for specific epoch
grep "Epoch 50" training.log

# Check best AUROC
grep "best AUROC" training.log
```

---

## ğŸ“Š Expected Results

Based on proposal targets:

| Metric | Target | Expected Range |
|--------|--------|----------------|
| Mean AUROC | >0.85 | 0.84-0.87 |
| Sensitivity (Critical) | >0.90 | 0.88-0.92 |
| Specificity | >0.85 | 0.83-0.88 |
| Inference Time | <10s | 6-8s (CPU) |
| F1 Score | - | 0.75-0.82 |

### Per-Class Performance (Expected)

Top performing classes:
- Cardiomegaly: AUROC ~0.90
- Effusion: AUROC ~0.88
- Mass: AUROC ~0.87

Challenging classes:
- Infiltration: AUROC ~0.70
- Nodule: AUROC ~0.75

---

## ğŸ› Troubleshooting

### Common Issues

**1. Out of Memory Error**

```bash
# Reduce batch size in config.py
BATCH_SIZE = 16  # or even 8

# Reduce number of workers
NUM_WORKERS = 2
```

**2. Dataset Not Found**

```bash
# Check data directory structure
ls -la data/raw/images/
ls -la data/raw/Data_Entry_2017.csv

# If missing, re-download dataset
```

**3. Model Loading Error**

```bash
# Check if model file exists
ls -la models/best_model.pth

# If missing, complete training first
python src/train.py
```

**4. Streamlit Won't Start**

```bash
# Reinstall Streamlit
pip install --upgrade streamlit

# Clear cache
streamlit cache clear

# Run with verbose logging
streamlit run streamlit_app/app.py --logger.level=debug
```

**5. Import Errors**

```bash
# Ensure virtual environment is activated
source venv/bin/activate

# Reinstall requirements
pip install -r requirements.txt --force-reinstall
```

### Performance Optimization

**For Apple Silicon Macs:**

```python
# In config.py, use MPS backend
import torch
DEVICE = torch.device('mps' if torch.backends.mps.is_available() else 'cpu')
```

**For Intel Macs with AMD GPU:**

```bash
# Use CPU (AMD GPUs not supported by PyTorch)
# Expect longer training times
```

---

## ğŸ“ Testing

```bash
# Run unit tests
python -m pytest tests/

# Test model architecture
python src/model.py

# Test data preprocessing
python src/data_preprocessing.py

# Test Grad-CAM
python src/gradcam.py --test-mode
```

---

## ğŸ“ˆ Creating Jupyter Notebooks for Analysis

```bash
# Install Jupyter
pip install jupyter notebook

# Start Jupyter
jupyter notebook

# Create new notebook in notebooks/ folder
```

**Useful Notebooks:**
- Data exploration and visualization
- Model performance analysis
- Error analysis
- Grad-CAM quality assessment

---

## ğŸ”¬ Advanced Usage

### Custom Training Script

```python
# train_custom.py
from src.config import Config
from src.model import create_model
from src.data_preprocessing import create_data_loaders
from src.train import Trainer

config = Config()
config.NUM_EPOCHS = 50  # Custom epochs
config.LEARNING_RATE = 5e-5  # Custom LR

train_loader, val_loader, _ = create_data_loaders(config)
trainer = Trainer(config)
trainer.train(train_loader, val_loader)
```

### Ensemble Models

```python
# Load multiple models for ensemble
models = []
for i in range(1, 6):
    model = create_model(config)
    load_checkpoint(f'models/checkpoint_fold_{i}.pth', model)
    models.append(model)

# Average predictions
predictions = torch.stack([m(x) for m in models]).mean(dim=0)
```

### Custom Evaluation Metrics

```python
# Add to evaluate.py
from sklearn.metrics import matthews_corrcoef

def compute_mcc(labels, predictions):
    binary_preds = (predictions >= 0.5).astype(int)
    return matthews_corrcoef(labels.ravel(), binary_preds.ravel())
```

---

## ğŸ“š References & Resources

### Dataset
- NIH ChestX-ray14: https://nihcc.app.box.com/v/ChestXray-NIHCC
- Wang et al. (2017): ChestX-ray8 paper

### Architecture
- DenseNet: Huang et al. (2017)
- Squeeze-and-Excitation: Hu et al. (2018)
- Grad-CAM: Selvaraju et al. (2017)

### Documentation
- PyTorch: https://pytorch.org/docs/
- Streamlit: https://docs.streamlit.io/
- scikit-learn: https://scikit-learn.org/

---

## ğŸ“§ Support

For issues or questions:
1. Check Troubleshooting section above
2. Review training logs
3. Check TensorBoard metrics
4. Contact supervisor via module page

---

## ğŸ“„ License & Ethics

This project is for educational purposes only.
- Ethics approval obtained: See proposal document
- Patient data handled according to NHS guidelines
- AI system intended for decision support, not replacement of clinical judgment

---

## âœ… Project Checklist

Before final submission, ensure:

- [ ] Dataset downloaded and preprocessed
- [ ] Model trained for minimum 50 epochs
- [ ] Best AUROC >0.83 achieved
- [ ] Test set evaluation complete
- [ ] Grad-CAM visualizations generated (50+ samples)
- [ ] Streamlit interface functional
- [ ] All plots saved in results/figures/
- [ ] Metrics reports generated
- [ ] Training logs preserved
- [ ] Code commented and documented
- [ ] README.md complete
- [ ] Supervisor meetings documented in appendices

---

**Good luck with your project! ğŸ“**

Last Updated: 2025
Student ID: 15700249